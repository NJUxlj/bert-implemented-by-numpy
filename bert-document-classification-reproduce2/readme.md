## å¤ç°å¹¶æ”¹è¿›ä¸€ç¯‡è®ºæ–‡ï¼šEnriching BERT with Knowledge Graph Embeddings for Document Classification

### åŸé¡¹ç›®åœ°å€
[pytorch-bert-document-classification](https://github.com/malteos/pytorch-bert-document-classification)

### è®ºæ–‡åœ°å€ï¼š
[Enriching BERT with Knowledge Graph Embeddings for Document Classification](https://arxiv.org/abs/1909.08402)


### é¡¹ç›®å†…å®¹
- æœ¬é¡¹ç›®ä¸»è¦ç ”ç©¶ä½¿ç”¨ç®€çŸ­æè¿°æ€§æ–‡æœ¬ï¼ˆå°é¢ç®€ä»‹ï¼‰å’Œé™„åŠ å…ƒæ•°æ®å¯¹ä¹¦ç±è¿›è¡Œåˆ†ç±»ã€‚

- ä½œè€…æ¼”ç¤ºäº†å¦‚ä½•å°†æ–‡æœ¬è¡¨ç¤ºï¼ˆtext-representationï¼‰ä¸å…ƒæ•°æ®(meta-data)å’ŒçŸ¥è¯†å›¾åµŒå…¥(knowledge-graph-embeddings)ç›¸ç»“åˆï¼Œå¹¶ä½¿ç”¨ä¸Šè¿°æ‰‹æ®µå¯¹ä½œè€…ä¿¡æ¯è¿›è¡Œç¼–ç ã€‚
- è¯„æµ‹é›†ï¼š2019 GermEval shared task on hierarchical text classification ï¼ˆå³ï¼Œå…±äº«ä»»åŠ¡æ•°æ®é›†ï¼‰
- æˆ‘ä»¬é‡‡ç”¨BERTè¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼Œå¹¶åœ¨å…±äº«ä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¸­æä¾›é¢å¤–çš„å…ƒæ•°æ®æ¥æ‰©å±•æ¨¡å‹ï¼Œå¦‚ä½œè€…ã€å‡ºç‰ˆå•†ã€å‡ºç‰ˆæ—¥æœŸç­‰ã€‚

- æ³¨æ„ï¼Œä½œè€…ä»…ä»…ä½¿ç”¨äº†ä¹¦çš„ç®€ä»‹æ¥ä½œä¸ºåˆ†ç±»æ¨¡å‹çš„è¾“å…¥ã€‚


### é¡¹ç›®ä¸»è¦è´¡çŒ®
- ä½¿ç”¨æœ€å…ˆè¿›çš„æ–‡æœ¬å¤„ç†æ–¹æ³•çº³å…¥äº†é¢å¤–çš„ï¼ˆå…ƒæ•°æ®ï¼‰æ•°æ®ã€‚

### æ•°æ®é›†å’Œä»»åŠ¡
- 2019 GermEval shared task on hierarchical text classification
- ä¸€ä¸ªåŒ…å«äº†20784æœ¬å¾·è¯­ä¹¦çš„æ•°æ®é›†
- æ¯è¡Œè®°å½• = {title, author_list, blurbç®€ä»‹, ä¹¦ç±URL, ISBN, å‡ºç‰ˆæ—¥æœŸ}
- æ‰€æœ‰ä¹¦ä½¿ç”¨äº†å¾·å›½å‡ºç‰ˆå•†å…°ç™»ä¹¦å±‹ä½¿ç”¨çš„åˆ†ç±»æ³•è¿›è¡Œæ ‡è®°ã€‚{ä¸€çº§ç±»åˆ«:8ä¸ªç±»åˆ«, äºŒçº§ç±»åˆ«:93ï¼Œ ä¸‰çº§ç±»åˆ«:242}
- æ¯ä¸ªå…±äº«ä»»åŠ¡ = å­ä»»åŠ¡A + å­ä»»åŠ¡B.
- å­ä»»åŠ¡Aï¼šæ˜¯ä¸€ä¸ªå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ï¼Œä»8ä¸ªç±»åˆ«ä¸­é€‰å‡ºå¤šä¸ª
- å­ä»»åŠ¡Bï¼šä¹Ÿæ˜¯å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ï¼Œä»äºŒçº§+ä¸‰çº§çš„æ€»å…±343ä¸ªç±»åˆ«ä¸­é€‰å‡ºå¤šä¸ªã€‚

### åŸæ–‡æ¨¡å‹ç»“æ„
1. æ–°æ¨¡å‹ = åŸå§‹Bertæ¨¡å‹+åŒå±‚MLPåˆ†ç±»å™¨+è¾“å‡ºå±‚softmax
2. è¾“å…¥æ•°æ®åˆ†ä¸ºä¸¤ç§ï¼šæ–‡æœ¬ç‰¹å¾ã€éæ–‡æœ¬ç‰¹å¾ã€‚
3. æ–‡æœ¬ç‰¹å¾ï¼šæ ‡é¢˜+ç®€ä»‹ï¼Œä¸è¶…è¿‡300 tokens
4. éæ–‡æœ¬ç‰¹å¾åŒ…å«ï¼š{å…ƒæ•°æ®ç‰¹å¾(meta-data featureï¼š10ç»´å‘é‡ï¼ˆå…¶ä¸­æœ‰2ç»´ä»£è¡¨æ€§åˆ«ï¼‰ã€ä½œè€…ä¿¡æ¯åµŒå…¥(author embedding)ï¼š200ç»´å‘é‡}
5. genderå­—æ®µå–å€¼ï¼šProbability of first author being male or female based on the **Gender-by-Name** dataset
6. Bertæ¨¡å‹çš„è¾“å…¥æ ¼å¼ = ä¹¦ç±æ ‡é¢˜+ä¹¦ç±ç®€ä»‹ï¼Œ
7. MLPåˆ†ç±»å™¨çš„è¾“å…¥ï¼šbertçš„è¾“å‡º+å…ƒæ•°æ®ç‰¹å¾+ä½œè€…ä¿¡æ¯åµŒå…¥
![image](https://github.com/user-attachments/assets/9bc7a6a2-bf28-49c6-97be-5bbaf3d401e9)


### è®­ç»ƒè¿‡ç¨‹
```python
batch_size b= 16
dropout probability d = 0.1
learning rate Î· = 2âˆ’5 (Adam optimizer)
training epochs = 5

æ‰€æœ‰å®éªŒéƒ½åœ¨GeForce GTX 1080 Tiï¼ˆ11 GBï¼‰ä¸Šè¿è¡Œï¼Œå› æ­¤å•ä¸ªè®­ç»ƒå‘¨æœŸæœ€å¤šéœ€è¦10åˆ†é’Ÿã€‚
å¦‚æœæ²¡æœ‰ä¸€ä¸ªæ ‡ç­¾çš„é¢„æµ‹æ¦‚ç‡é«˜äºåˆ†ç±»é˜ˆå€¼ï¼Œåˆ™ä½¿ç”¨æœ€æµè¡Œçš„æ ‡ç­¾ï¼ˆæ¯”å¦‚ï¼šæ–‡å­¦å’Œéæ–‡åŒ–ï¼‰ä½œä¸ºé¢„æµ‹ã€‚
```

### å¦‚ä½•è¿è¡ŒåŸé¡¹ç›®

####
å‘½ä»¤è¡Œç¯å¢ƒå˜é‡
- TRAIN_DF_PATH: Path to Pandas Dataframe (pickle)
- GPU_ID: Run experiments on this GPU (used for CUDA_VISIBLE_DEVICES)
- OUTPUT_DIR: Directory to store experiment output
- EXTRAS_DIR: Directory where author embeddings and gender data is located
- BERT_MODELS_DIR: Directory where pre-trained BERT models are located

Validation set
```shell
python cli.py run_on_val <name> $GPU_ID $EXTRAS_DIR $TRAIN_DF_PATH $VAL_DF_PATH $OUTPUT_DIR --epochs 5
```

Test set
```shell
python cli.py run_on_test <name> $GPU_ID $EXTRAS_DIR $FULL_DF_PATH $TEST_DF_PATH $OUTPUT_DIR --epochs 5
```

Evaluation
```shell
The scores from the result table can be reproduced with the evaluation.ipynb notebook.
```


#### ä¸‹è½½wikidata_translation_v1.tsv.gzæ•°æ®é›†
![Snipaste_2024-09-08_12-11-48](https://github.com/user-attachments/assets/10c8e271-9cc0-4567-8986-5c486197aada)



### ä½¿ç”¨WikiMapperåˆ›å»ºWikiç´¢å¼•

```shell
pip install wikimapper

# åˆ›å»º index_enwiki-latest.db

wikimapper download enwiki-latest --dir wikidata

wikimapper create enwiki-latest --dumpdir wikidata --target wikidata/index_enwiki-latest.db

# åˆ›å»º index_dewiki-latest.db
wikimapper download dewiki-latest --dir wikidata

wikimapper create dewiki-latest --dumpdir wikidata --target wikidata/index_dewiki-latest.db
```

#### åŠ è½½ authors.pickle
æ‰“å¼€germeval-data.ipynb
ä¸€ç›´è¿è¡Œç›´åˆ°ç¬¬75ä¸ªä»£ç cell
![image](https://github.com/user-attachments/assets/fa4667a8-0e2f-497d-b59e-b63633676018)



### åŸå®éªŒç»“æœ
- ä½¿ç”¨é¢å¤–çš„å…ƒæ•°æ®ç‰¹å¾å’Œä½œè€…ä¿¡æ¯åµŒå…¥çš„BERT-Germançš„è®¾ç½®ä¼˜äºæ‰€æœ‰å…¶ä»–è®¾ç½®
- ä»»åŠ¡Açš„F1å¾—åˆ†ä¸º87.20ï¼Œä»»åŠ¡Bçš„F1å¾—åˆ†æ˜¯64.70
![image](https://github.com/user-attachments/assets/664fbea3-fcc1-4c0b-bced-862b910bd911)



### æˆ‘åšå‡ºäº†å¦‚ä¸‹æ”¹è¿›
- ç”±äºé˜¿é‡Œäº‘DSWå®ä¾‹çš„ç½‘ç»œé—®é¢˜ï¼Œæˆ‘æ— æ³•è®¿é—®huggingfaceã€‚
- å› æ­¤ä½¿ç”¨bert-base-chinese ä»£æ›¿ bert-base-german
#### æ”¹è¿›1
- åŸå§‹é¡¹ç›®ä½¿ç”¨äº†å¾·è¯­å†™çš„ä¹¦ç±çš„ç®€ä»‹ä½œä¸ºè¯­æ–™ï¼Œå¹¶ä¸”æœ€ç»ˆé¢„è®­ç»ƒäº†ä¸€ä¸ªå¾·è¯­æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ¨¡å‹æ˜¯åœ¨å¾·å›½ç»´åŸºç™¾ç§‘ã€æ–°é—»æ–‡ç« å’Œæ³•é™¢åˆ¤å†³ä¹¦ä¸Šä»å¤´å¼€å§‹è®­ç»ƒçš„ã€‚
- æˆ‘å°†è®­ç»ƒè¯­æ–™æ”¹ä¸ºä¸­æ–‡ï¼Œå¹¶ä¸”æƒ³è¾“å…¥æ ¼å¼ä¸å›½å†…ä¹ æƒ¯ç›¸åŒ¹é…ã€‚
- **å·²æŠ›å¼ƒ**


#### æ”¹è¿›2
å…±äº«æ•°æ®é›†çš„åˆ†ç±»æ³•æ— æ³•æ‰¾åˆ°ä¸­æ–‡çš„ç›¸ä¼¼çš„ç‰ˆæœ¬ï¼Œå› æ­¤æˆ‘æš‚æ—¶åªèƒ½åœ¨ text-feature, extra featrue è¿™ä¸¤å—ç‰¹å¾çš„ç»„åˆä¸Šåšæ–‡ç« 

#### PCA


#### forward featrue selection 




#### æ”¹è¿›3
- æˆ‘ä»¬æ”¹è¿›æ¨¡å‹çš„æ¶æ„
- åŸå§‹æ¨¡å‹é‡‡ç”¨äº† BERT + MLP + softmax

  - åŸå§‹çš„BERTè®ºæ–‡æå‡ºï¼Œåœ¨ä»å·¦åˆ°å³æ¨¡å‹(LTR)é¡¶ä¸ŠåŠ ä¸ŠBiLSTMå±‚åï¼Œæ€§èƒ½ä»ç„¶æ— æ³•è¶…è¿‡BERT, åŒæ—¶è®ºæ–‡æå‡ºå¹¶è¯æ˜BiLSTMä¼šä¼¤å®³GLUEæ•°æ®é›†ä¸Šçš„è¡¨ç°
  - å¦å¤–ï¼Œåœ¨æŸäº›ä¿¡æ¯æ¥æºä¸­ï¼ŒBERT+BiLSTMçš„è¡¨ç°ç”šè‡³ä¸å¦‚åŸå§‹BERT
  - æˆ‘ä»¬åˆ†æï¼Œ åœ¨ä¸€äº›æ–‡æœ¬åˆ†ç±»ä»»åŠ¡é‡ï¼Œ åŒå‘ç¼–ç å¯èƒ½å¹¶ä¸æ˜¯å¿…è¦çš„ï¼Œå¯èƒ½ä¼šäº§ç”Ÿå¯¹ç›®æ ‡tokençš„è¿‡åº¦é¢„æµ‹ï¼Œå› æ­¤æœ‰å¿…è¦å®éªŒåŸå§‹çš„LSTMï¼Œ åŒæ—¶ä¿ç•™è¯­åºä¿¡æ¯ã€‚
  - å¦å¤–ï¼Œ TextCNNåœ¨poolingæ—¶ä¹Ÿèƒ½æœ‰æ•ˆä¿ç•™è¯­åºä¿¡æ¯ã€‚

- å› æ­¤ï¼Œæˆ‘æå‡ºè¦ä½¿ç”¨
BERT + TextRCNN(LSTM+TextCNN) + MLP + SoftMAX


```python

class ExtraBertTextRCNNMultiClassifier(nn.Module):
    def __init__(self, bert_model_path, labels_count, rnn_hidden_dim=256, cnn_kernel_size=3,   
                 rnn_type='LSTM', num_layers=1, hidden_dim=768, mlp_dim=256, extras_dim=6, dropout=0.1):  
        super(ExtraBertTextRCNNMultiClassifier, self).__init__()  

        # å­˜å‚¨æ¨¡å‹çš„è¶…å‚æ•°  
        self.config = {  
            'bert_model_path': bert_model_path,  
            'labels_count': labels_count,  
            'rnn_hidden_dim': rnn_hidden_dim,  
            'cnn_kernel_size': cnn_kernel_size,  
            'rnn_type': rnn_type,  
            'num_layers': num_layers,  
            'hidden_dim': hidden_dim,  
            'mlp_dim': mlp_dim,  
            'extras_dim': extras_dim,  
            'dropout': dropout  
        }  

        self.bert = BertModel.from_pretrained(bert_model_path)  

        # åˆå§‹åŒ–RNNï¼ˆå¯ä»¥æ˜¯LSTMï¼‰        
        self.rnn = nn.LSTM(input_size=hidden_dim, hidden_size=rnn_hidden_dim,  
                           num_layers=num_layers, batch_first=True, bidirectional=True)  

        # åˆå§‹åŒ–CNNå±‚ç”¨äºç‰¹å¾æå–  
        self.cnn = nn.Conv1d(in_channels=2 * rnn_hidden_dim,  # å› ä¸ºæ˜¯åŒå‘LSTM  
                             out_channels=rnn_hidden_dim,  
                             kernel_size=cnn_kernel_size,  
                             padding=cnn_kernel_size // 2)  

      
        self.dropout = nn.Dropout(dropout)  

        # MLPå…¨è¿æ¥å±‚  
        self.mlp = nn.Sequential(  
            nn.Linear(rnn_hidden_dim + extras_dim, mlp_dim),  
            nn.ReLU(),  
            nn.Linear(mlp_dim, mlp_dim),  
            nn.ReLU(),  
            nn.Linear(mlp_dim, labels_count)  
        )  

        # Softmaxå±‚ç”¨äºè¾“å‡ºæ¦‚ç‡  
        self.softmax = nn.Softmax(dim=1)  

    def forward(self, tokens, masks, extras):  
        '''  
        tokens: [batch_size, seq_len, hidden_dim]  
        masks: [batch_size, seq_len]  
        extras: [batch_size, extras_dim]  
        '''  
        # é€šè¿‡BERTæ¨¡å‹è·å–æœ€åä¸€ä¸ªéšè—å±‚çš„è¾“å‡ºå’Œæ± åŒ–è¾“å‡º  
        sequence_output, _ = self.bert(tokens, attention_mask=masks, return_dict=False)  
        
        # é€šè¿‡RNN  
        rnn_output, _ = self.rnn(sequence_output)  

        # è½¬æ¢ç»´åº¦ä½¿å…¶é€‚åº”å·ç§¯å±‚ (batch_size, channels, seq_len)  
        rnn_output = rnn_output.permute(0, 2, 1)  

        # é€šè¿‡å·ç§¯å±‚æå–ç‰¹å¾  
        cnn_output = self.cnn(rnn_output)  

        # è½¬æ¢å·ç§¯è¾“å‡ºç»´åº¦  
        cnn_output = cnn_output.permute(0, 2, 1)  

        # æå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾ä½œä¸ºæ–‡æœ¬ç‰¹å¾  
        text_features = torch.mean(cnn_output, dim=1)  

        dropout_output = self.dropout(text_features)  

        concat_output = torch.cat([dropout_output, extras], dim=1)  

        mlp_output = self.mlp(concat_output)  

        # è¾“å‡ºæ¦‚ç‡  
        proba = self.softmax(mlp_output)  

        return proba  



```

- åæœŸï¼Œæˆ‘ä»¬ä¹Ÿä¼šåŠ å…¥Diyçš„BERTï¼ˆçº¯numpyå®ç°ï¼‰


#### æ”¹è¿›4
- æ ¹æ®è®ºæ–‡çš„è¯´æ³•ï¼Œåœ¨æ‰€æœ‰çš„å®éªŒè®¾ç½®ä¸­ï¼ˆsub-taskA,B + text-feature or not + extra-features or not), 
æ¨¡å‹çš„ç²¾ç¡®ç‡éƒ½æ˜¾è‘—é«˜äºå¬å›ç‡ã€‚
- ä½œè€…è®¤ä¸ºï¼Œå¯¹äºå­ä»»åŠ¡Bä¸­çš„343ä¸ªæ ‡ç­¾ä¸­çš„ä¸€äº›ï¼Œå®ä¾‹å¾ˆå°‘ã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœåˆ†ç±»å™¨é¢„æµ‹æŸä¸ªæ ‡ç­¾ï¼Œå®ƒå¾ˆå¯èƒ½æ˜¯æ­£ç¡®çš„ï¼ˆå³é«˜ç²¾åº¦ï¼‰ï¼Œä½†å¯¹äºè®¸å¤šå…·æœ‰ä½é¢‘æ ‡ç­¾çš„æƒ…å†µï¼Œè¿™ä¸ªä½é¢‘æ ‡ç­¾æ°¸è¿œä¸ä¼šè¢«é¢„æµ‹ï¼ˆå³ä½å¬å›ç‡ï¼‰ã€‚ğŸ”¤

##### è§£å†³æ ‡ç­¾ä¸å‡è¡¡é—®é¢˜
1.**è¿‡é‡‡æ ·** å¤åˆ¶æŒ‡å®šç±»åˆ«çš„æ ·æœ¬ï¼Œåœ¨é‡‡æ ·ä¸­é‡å¤
2.**é™é‡‡æ ·** å‡å°‘å¤šæ ·æœ¬ç±»åˆ«çš„é‡‡æ ·ï¼Œéšæœºä½¿ç”¨éƒ¨åˆ†



### å®éªŒç»“æœ









### Reference
```latex
@inproceedings{Ostendorff2019,
    address = {Erlangen, Germany},
    author = {Ostendorff, Malte and Bourgonje, Peter and Berger, Maria and Moreno-Schneider, Julian and Rehm, Georg},
    booktitle = {Proceedings of the GermEval 2019 Workshop},
    title = {{Enriching BERT with Knowledge Graph Embedding for Document Classification}},
    year = {2019}
}


```
